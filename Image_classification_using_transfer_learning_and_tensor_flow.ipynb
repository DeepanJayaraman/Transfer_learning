{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image classification using transfer learning and tensor flow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOIzt8U/v4UBF8gZdd5wz1U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepanJayaraman/Transfer_learning/blob/main/Image_classification_using_transfer_learning_and_tensor_flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJGc85sQWrtr"
      },
      "source": [
        "# Install tensor flow hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48abbzVHWm2U",
        "outputId": "694bd22e-4ed1-4e25-8957-c27963db4323"
      },
      "source": [
        "!pip install \"tensorflow_hub\""
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (3.12.4)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow_hub) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow_hub) (56.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCn6nEXdWbm0"
      },
      "source": [
        "# Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhP9UnMdWQP9"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o31V-gjlXw4U"
      },
      "source": [
        "# Import mobilenet model for transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPjo8HG5XvsS"
      },
      "source": [
        "Class_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/2\"\n",
        "Im_res = 224"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBeIX2msYaKa"
      },
      "source": [
        "Set predefined layer for TL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb-QKOSzYiHq"
      },
      "source": [
        "TL_layer = hub.KerasLayer(Class_URL,input_shape=(Im_res,Im_res,3))\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYs0YyvdaQ0S"
      },
      "source": [
        "Load data set for classification from tf data sets\n",
        "cats_dogs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GV2lIuxaZBD"
      },
      "source": [
        "(train_img,vald_img), info = tfds.load('cats_vs_dogs',as_supervised=True,with_info=True,split=['train[:80%]', 'train[80%:]'])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF2Q7zXbcYXC"
      },
      "source": [
        "Data size and no. of features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmdD30mncNXq"
      },
      "source": [
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsqotpcieDqi"
      },
      "source": [
        "Randomly check some image sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SVi6bzgeHxJ",
        "outputId": "38e60d98-02dd-43da-cc91-9bc4bcfe1360"
      },
      "source": [
        "for i,image in enumerate(train_img.take(5)):\n",
        "  print(\"image: {}, Size: {}\".format(i+1,image[0].shape))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image: 1, Size: (262, 350, 3)\n",
            "image: 2, Size: (409, 336, 3)\n",
            "image: 3, Size: (493, 500, 3)\n",
            "image: 4, Size: (375, 500, 3)\n",
            "image: 5, Size: (240, 320, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze60n3DYe3Ga"
      },
      "source": [
        "Write funciton to resize the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8odLdX2e6jJ"
      },
      "source": [
        "def im_resize(img,label):\n",
        "  img = tf.image.resize(img,(Im_res,Im_res))/255 # Normalize\n",
        "  return img,label"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyBOlRyciAJr"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_batches      = train_img.shuffle(num_examples//4).map(im_resize).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = vald_img.map(im_resize).batch(BATCH_SIZE).prefetch(1)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UCI9dBPim2Z"
      },
      "source": [
        "image_batch, label_batch = next(iter(train_batches.take(1)))\n",
        "image_batch = image_batch.numpy()\n",
        "label_batch = label_batch.numpy()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE29p99egvXA"
      },
      "source": [
        "# Batch size extract from the data set\n",
        "feature_batch = TL_layer(image_batch)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHJwQNM6jDKJ"
      },
      "source": [
        "# Freeze the layer: So that the tranfer learning model parameters will not change"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jNuIZKGjQX6"
      },
      "source": [
        "TL_layer.trainable=False"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AWqKY4MjY33"
      },
      "source": [
        "Layer assigning for output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8DOWT4Njd2T"
      },
      "source": [
        "out_layer = tf.keras.layers.Dense(2)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I5DTADpkoz_"
      },
      "source": [
        "Attach the layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWNNITRkhB3Y"
      },
      "source": [
        "model = tf.keras.Sequential([TL_layer,out_layer])"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU3OcDnllbtQ"
      },
      "source": [
        "# Training model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpyNvIUCku5R"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5AyGDzHkyAS"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1XWtkfNmKJY"
      },
      "source": [
        "Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj7EAmzLloYs",
        "outputId": "a12ff72e-90e2-4be3-921b-ac132b56c1ad"
      },
      "source": [
        "History = model.fit(train_batches,\n",
        "          epochs=8,\n",
        "          validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "582/582 [==============================] - 1188s 2s/step - loss: 0.1331 - accuracy: 0.9529 - val_loss: 0.0357 - val_accuracy: 0.9890\n",
            "Epoch 2/8\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9892"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnaIkNaxm2s1"
      },
      "source": [
        "Check accuracy and losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d28dhbFpr98b"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBqshdconwQY"
      },
      "source": [
        ""
      ]
    }
  ]
}